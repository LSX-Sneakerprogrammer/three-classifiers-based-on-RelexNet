{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"relexnet without modifier final model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNOvOnoN+zietmxL8hFnxpi"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rq-8cdE6uSVj","executionInfo":{"status":"ok","timestamp":1622465743877,"user_tz":-480,"elapsed":47274,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"c650d53e-3db6-4cd4-ead3-2aa577c2dc6d"},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 160706 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.26-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPU2-Bjaw3if","executionInfo":{"status":"ok","timestamp":1622465750780,"user_tz":-480,"elapsed":533,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"00ae784e-b444-4a0e-efe8-2550f9a14af9"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon May 31 12:55:50 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bWU91uoOxa0F"},"source":["!mkdir -p drive\n","!google-drive-ocamlfuse -o nonempty drive\n","import os\n","import sys\n","os.chdir('drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"keypfrnLhTp5"},"source":["import nltk\n","from functools import lru_cache\n","import re\n","import string\n","import numpy as np\n","import pandas as pd\n","import torch\n","from collections import Counter, defaultdict\n","from sklearn.preprocessing import OneHotEncoder\n","import torch.utils.data as Data\n","import torch.nn.functional as F\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import os\n","import glob\n","from sklearn.utils import shuffle\n","import copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"knN_KDWrqNHX","executionInfo":{"status":"ok","timestamp":1622465765784,"user_tz":-480,"elapsed":10,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"5f512216-110e-4fed-f35d-91cfc139eb7b"},"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    # print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print(torch.cuda.device_count())\n","    print('Device name:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\n","Device name: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCiTJxaMqlt-","executionInfo":{"status":"ok","timestamp":1622465766451,"user_tz":-480,"elapsed":672,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"81da7187-88b5-4dbc-bed9-dda11302ce82"},"source":["!/opt/bin/nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon May 31 12:56:05 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    27W / 250W |      2MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F36OHIItkZpx"},"source":["class Modifiers:\n","    def __init__(self):\n","        # modifier and negative word dictionary copyright@cjhutto https://github.com/cjhutto/vaderSentiment\n","        C_INCR = 0.733\n","        B_INCR = 0.293\n","        B_DECR = -0.293\n","\n","        N_SCALAR = -0.74\n","        self.NEGATE = \\\n","            [\"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\", \"didnt\", \"doesnt\",\n","             \"ain't\", \"aren't\", \"can't\", \"couldn't\", \"daren't\", \"didn't\", \"doesn't\",\n","             \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\", \"neither\",\n","             \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\",\n","             \"neednt\", \"needn't\", \"never\", \"none\", \"nope\", \"nor\", \"not\", \"nothing\", \"nowhere\",\n","             \"oughtnt\", \"shant\", \"shouldnt\", \"uhuh\", \"wasnt\", \"werent\",\n","             \"oughtn't\", \"shan't\", \"shouldn't\", \"uh-uh\", \"wasn't\", \"weren't\",\n","             \"without\", \"wont\", \"wouldnt\", \"won't\", \"wouldn't\", \"rarely\", \"seldom\", \"despite\"]\n","\n","        # booster/dampener 'intensifiers' or 'degree adverbs'\n","        # http://en.wiktionary.org/wiki/Category:English_degree_adverbs\n","\n","        self.BOOSTER_DICT = \\\n","            {\"absolutely\": B_INCR, \"amazingly\": B_INCR, \"awfully\": B_INCR, \"completely\": B_INCR, \"considerably\": B_INCR,\n","             \"decidedly\": B_INCR, \"deeply\": B_INCR, \"effing\": B_INCR, \"enormously\": B_INCR,\n","             \"entirely\": B_INCR, \"especially\": B_INCR, \"exceptionally\": B_INCR, \"extremely\": B_INCR,\n","             \"fabulously\": B_INCR, \"flipping\": B_INCR, \"flippin\": B_INCR,\n","             \"fricking\": B_INCR, \"frickin\": B_INCR, \"frigging\": B_INCR, \"friggin\": B_INCR, \"fully\": B_INCR,\n","             \"fucking\": B_INCR,\n","             \"greatly\": B_INCR, \"hella\": B_INCR, \"highly\": B_INCR, \"hugely\": B_INCR, \"incredibly\": B_INCR,\n","             \"intensely\": B_INCR, \"majorly\": B_INCR, \"more\": B_INCR, \"most\": B_INCR, \"particularly\": B_INCR,\n","             \"purely\": B_INCR, \"quite\": B_INCR, \"really\": B_INCR, \"remarkably\": B_INCR,\n","             \"so\": B_INCR, \"substantially\": B_INCR,\n","             \"thoroughly\": B_INCR, \"totally\": B_INCR, \"tremendously\": B_INCR,\n","             \"uber\": B_INCR, \"unbelievably\": B_INCR, \"unusually\": B_INCR, \"utterly\": B_INCR,\n","             \"very\": B_INCR,\n","             \"almost\": B_DECR, \"barely\": B_DECR, \"hardly\": B_DECR, \"just enough\": B_DECR,\n","             \"kind of\": B_DECR, \"kinda\": B_DECR, \"kindof\": B_DECR, \"kind-of\": B_DECR,\n","             \"less\": B_DECR, \"little\": B_DECR, \"marginally\": B_DECR, \"occasionally\": B_DECR, \"partly\": B_DECR,\n","             \"scarcely\": B_DECR, \"slightly\": B_DECR, \"somewhat\": B_DECR,\n","             \"sort of\": B_DECR, \"sorta\": B_DECR, \"sortof\": B_DECR, \"sort-of\": B_DECR}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"by-7uhU7n1cs"},"source":["class Preprocessor:\n","    def clean_text(self, text):\n","        # '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n","        # make text lowercase\n","        text1 = text.lower()\n","        # remove square brackets\n","        text1 = re.sub('\\[.*?\\]', '', text1)\n","        #remove <>\n","        text1 = re.sub('<.*?>+', '', text1)\n","        text1 = re.sub('\\(.*?\\)', ' ', text1)\n","        text1 = re.sub('\\{.*?\\}', ' ', text1)\n","        # remove links\n","        text1 = re.sub('https?://\\S+|www\\.\\S+', ' ', text1)\n","        # remove punctuation\n","        text1 = re.sub('[%s]' % re.escape(string.punctuation), '', text1)\n","        # remove \\n\n","        # text = re.sub('\\n', '', text)\n","        # remove numbers\n","        text = re.sub('\\w*\\d\\w*', '', text)\n","        return text1\n","\n","    def __init__(self):\n","        self.stem = lru_cache(maxsize=10000)(nltk.stem.SnowballStemmer('english').stem)\n","        # self.stopwords = stopwords.words('english')\n","        self.tokenize = nltk.tokenize.TreebankWordTokenizer().tokenize\n","\n","    def __call__(self, text):\n","        text1 = self.clean_text(text)\n","        tokens = self.tokenize(text1)\n","        # tokens = [token for token in tokens if token not in self.stopwords]\n","        # tokens = [self.stem(token) for token in tokens]\n","\n","        return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jxP_rB3xoeLK"},"source":["\n","class DataLoader:\n","    def __init__(self, data, batch_size, k, context_window = 1, preprocessor=Preprocessor(), enc_tokens = OneHotEncoder(), dev = 'cpu'):\n","        self.df = data\n","        self.dev = dev\n","        self.batch_size = batch_size\n","        self.context_window = context_window\n","        # self.modifiers = modifier.BOOSTER_DICT.keys()\n","        # self.enc_modifiers = enc_modifiers\n","        # self.vocab_frequency = 5\n","        self.padding_length = 75\n","        self.fold_num = 10\n","        # self.padding_length = 192\n","        # self.first_sentence = 128\n","        # self.second_sentence = self.padding_length - self.first_sentence\n","\n","        self.apply_preprocessor(preprocessor)\n","        enc_tokens.fit(self.vocab)\n","        # self.split(0.4, 0.3)\n","        # print(len(self.test))\n","        self.split(0.9, 0.1)\n","\n","        # self.k_fold_partition(fold_num = self.fold_num) # Divide ten folds\n","        # print(\"K Fold Partition Completed!\")\n","        # train, validation = self.k_fold_split(k)\n","        \n","        train_num = len(self.train)\n","        if train_num % self.batch_size == 0:\n","            self.no_batch = train_num / self.batch_size\n","        else:\n","            self.no_batch = int(train_num / self.batch_size) + 1\n","\n","        trainX, trainY = self.build_training_data(enc_tokens, self.train)\n","        # trainX, trainY = self.build_training_data(enc_tokens, train)\n","\n","        # validationX, validationY = self.build_training_data(enc_tokens, validation)\n","        testX, testY = self.build_training_data(enc_tokens, self.test)\n","        print(f'Train Dataset Shape : {trainX.shape}')\n","        # print(f'Validation Dataset Shape : {validationX.shape}')\n","        print(f'Test Dataset Shape : {testX.shape}')\n","        self.train_dataset = self.get_batch(trainX, trainY)\n","        # self.validation_dataset = self.get_batch(validationX, validationY)\n","        self.test_dataset = self.get_batch(testX, testY)\n","\n","\n","    def get_batch(self, X, Y):\n","        dataset = Data.TensorDataset(X, Y)\n","        loader = Data.DataLoader(\n","            dataset=dataset,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            # num_workers=2,\n","        )\n","        return loader\n","        # train_dataset = Data.TensorDataset(self.train_X, self.train_Y)\n","        # valid_dataset = Data.TensorDataset(self.valid_X, self.valid_Y)\n","        # test_dataset = Data.TensorDataset(self.test_X, self.test_Y)\n","        # self.loader = Data.DataLoader(\n","        #     dataset=train_dataset,\n","        #     batch_size=self.batch_size,\n","        #     shuffle=True,\n","        #     # num_workers=2,\n","        # )\n","        # self.valid_dataset = Data.DataLoader(\n","        #     dataset=valid_dataset,\n","        #     # batch_size=self.batch_size,\n","        #     shuffle=True,\n","        #     # num_workers=2,\n","        # )\n","        # self.test_dataset = Data.DataLoader(\n","        #     dataset=test_dataset,\n","        #     # batch_size=self.batch_size,\n","        #     shuffle=True,\n","        #     # num_workers=2,\n","        # )\n","\n","\n","    def remove_low_frequency(self, list):\n","        new_list = []\n","        for x in list:\n","            if x in self.token_to_count.keys():\n","                new_list.append(x)\n","        return new_list\n","\n","\n","    def apply_preprocessor(self, preprocessor):\n","        self.df['tokens'] = [preprocessor(s) for s in self.df['sentence']]\n","        self.df['tokens'] = [x[:self.padding_length]  if len(x) > self.padding_length else x for x in self.df['tokens']]\n","\n","        # for index, row in self.df.iterrows():\n","        #     if len(row['tokens']) > self.max_length:\n","        #         row[toke]\n","\n","        self.token_to_count = Counter([x for l in self.df['tokens'] for x in l])\n","\n","        # tmp_token_to_count = self.token_to_count.copy()\n","        # for index, value in tmp_token_to_count.items():\n","        #     if value <= self.vocab_frequency:\n","        #         self.token_to_count.pop(index)\n","        # self.df['tokens'] = [self.remove_low_frequency(x) for x in self.df['tokens']]\n","        self.max_length = self.get_max_length()\n","        print(f'Max Length : {self.max_length}')\n","\n","        self.vocab = list([[term] for term in self.token_to_count.keys()])\n","\n","        print(f'Vocab Size : {len(self.vocab)}')\n","\n","    def get_max_length(self):\n","        max_length = 0\n","        for index, row in self.df.iterrows():\n","            ######## Changed part for negatives ###########\n","            token_list = [x for x in row['tokens']]\n","            ##############      End       #################\n","            tmp_length = len(token_list)\n","            if tmp_length > max_length:\n","                max_length = tmp_length\n","        return max_length\n","    def k_fold_partition(self, fold_num = 10):\n","        # index = list(range(len(self.df))) # total index\n","        batch_size = int(len(self.train) / fold_num) # the number of data for each fold\n","        remain_num = len(self.train) - batch_size * fold_num # the remain data after partition\n","        self.fold_data = []\n","        fold_batch_list = [] # Average the remaining data to the folds\n","        for fold in range(fold_num):\n","          if remain_num > 0:\n","            remain_num -= 1\n","            fold_batch_list.append(batch_size + 1)\n","          else:\n","            fold_batch_list.append(batch_size)\n","        fold_index = 0 # The starting position of each division data\n","        for fold in range(fold_num):\n","          fold_texts = [fold_index, fold_index + fold_batch_list[fold]]\n","          self.fold_data.append(fold_texts)\n","          fold_index = fold_index + fold_batch_list[fold]\n","\n","\n","    def k_fold_split(self, k):\n","        print(f'K : {k}, fold_data[k] : {self.fold_data[k]}')\n","        validation = self.train.iloc[self.fold_data[k][0]: self.fold_data[k][1]]\n","        train = self.train.iloc[0: self.fold_data[k][0]].append(self.train.iloc[self.fold_data[k][1]:])\n","        train_num = len(self.train) - (self.fold_data[k][1] - self.fold_data[k][0])\n","        if train_num % self.batch_size == 0:\n","            self.no_batch = train_num / self.batch_size\n","        else:\n","            self.no_batch = int(train_num / self.batch_size) + 1\n","        print(f' index : {self.no_batch}')\n","        return train, validation\n","\n","\n","    def split(self, train, test):\n","        index = int(train * len(self.df))\n","        self.train = self.df.iloc[0:index]\n","        self.test = self.df.iloc[index:]\n","        # if self.train_index % self.batch_size == 0:\n","        #     self.no_batch = self.train_index / self.batch_size\n","        # else:\n","        #     self.no_batch = int(self.train_index / self.batch_size) + 1\n","        # print(f' index : {self.no_batch}')\n","\n","    def build_training_data(self, enc, df):\n","        X = []\n","        Y = []\n","        for index, row in df.iterrows():\n","            tmp = [enc.transform([[t]]).toarray()[0] for t in row['tokens']]\n","            if len(tmp) < self.max_length:\n","                pad_length = self.max_length - len(tmp)\n","                for i in range(pad_length):\n","                    tmp.append(np.zeros(len(self.vocab)))\n","            X.append(tmp)\n","            Y.append(row['label'])\n","        X = np.array(X)\n","        Y = np.array(Y)\n","        X = torch.from_numpy(X).float()\n","        Y = torch.from_numpy(Y).long()\n","        print(f'Input Data Shape (sequence_num, sequence_len, vocab_size + 1) : {X.shape}')\n","        print(f'Input Label Shape : {Y.shape}')\n","        return X, Y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gOBWpAvWrAdh"},"source":["class RelexNet(nn.Module):\n","    #Single step RNN.\n","    #input_size is char_vacab_size=26,hidden_size is number of hidden neurons，output_size is number of categories\n","    def __init__(self, vocabulary_size, len_seq, num_classes):\n","        super(RelexNet, self).__init__()\n","        self.num_classes = num_classes\n","        self.L = nn.Linear(vocabulary_size, num_classes)\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input, B_layer):\n","        # X.shape = (batch, seq_len, vocab_size)\n","        T = input.shape[1]\n","        batch = input.shape[0]\n","        predict_y = Variable(torch.zeros(batch, self.num_classes))\n","\n","        if B_layer is None:\n","            B_layer = Variable(torch.zeros(batch, self.num_classes)).cuda()\n","\n","        for t in range(T):\n","            tmp = input[:, t, :]\n","\n","            L_onestep = self.L(tmp)\n","            L_onestep = self.dropout(L_onestep)\n","            # L_onestep = torch.sigmoid(L_onestep)\n","            L_onestep = F.relu6(L_onestep)\n","           \n","            B_layer = torch.add(B_layer, L_onestep)\n","            # print(B_layer)\n","\n","            if self.num_classes == 1:\n","                predict_y[t] = F.sigmoid(B_layer)\n","            else:\n","                predict_y = self.softmax(B_layer)\n","\n","        return predict_y, B_layer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rE53K7W8sP4K"},"source":["def train_model(dataset, model, optimizer, scheduler, num_epochs, dev):\n","    losses = []\n","    for epoch in range(num_epochs):\n","        # training mode\n","        # dataset.set_partition(dataset.train)\n","        model.train()\n","        total_train_loss = 0\n","        total_train_correct = 0\n","        count = 0\n","        for x, y in dataset.train_dataset:\n","            # for every batch in the training dataset perform one update step of the optimizer.\n","            state = None\n","            model.zero_grad()\n","            y_h, state = model(x.to(dev), state)\n","            loss = F.cross_entropy(y_h, y.to(dev))\n","            optimizer.zero_grad()\n","            # scheduler.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            # print('{} optim: {}'.format(epoch, optimizer.param_groups[0]['lr']))\n","            scheduler.step()\n","            # print('{} scheduler: {}'.format(epoch, scheduler.get_lr()[0]))\n","            total_train_loss += loss.item()\n","            total_train_correct += (y_h.argmax(-1) == y.cuda()).float().mean()\n","            count += 1\n","        average_train_loss = total_train_loss / count\n","        average_train_accuracy = total_train_correct / count\n","        losses.append(average_train_loss)\n","        print('{} optim: {}'.format(epoch + 1, optimizer.param_groups[0]['lr']))\n","        # print('{} optim: {}'.format(epoch, optimizer.param_groups[0]['lr']))\n","        # print('{} scheduler: {}'.format(epoch, scheduler.get_lr()[0]))\n","\n","        # validation mode\n","        # dataset.set_partition(dataset.valid)\n","\n","        # model.eval()\n","        # total_valid_loss = 0\n","        # total_valid_correct = 0\n","\n","        # # total_tp = 0\n","        # # total_fp = 0\n","        # # total_fn = 0\n","        # # total_tn = 0\n","        # count = 0\n","        # for x, y in dataset.test_dataset:\n","        #     state = None\n","        #     y_h, state = model(x.to(dev), state)\n","        #     loss = F.cross_entropy(y_h, y.to(dev))\n","\n","        #     total_valid_loss += loss.item()\n","        #     total_valid_correct += (y_h.argmax(-1) == y.cuda()).float().mean()\n","            \n","        #     # total_tp += float((y_h.argmax(-1) == y.cuda() & (y.cuda() == 1)).float())\n","        #     # total_fp += float((y_h.argmax(-1) != y.cuda() & (y.cuda() == 0)).float())\n","        #     # total_fn += float((y_h.argmax(-1) != y.cuda() & (y.cuda() == 1)).float())\n","        #     count += 1\n","        # average_valid_loss = total_valid_loss / count\n","        # # average_precision = total_tp / (total_tp + total_fp)\n","        # # average_recall = total_tp / (total_tp + total_fn)\n","        # losses.append((average_train_loss, average_valid_loss))\n","        # average_valid_accuracy = total_valid_correct / count\n","\n","        print(f'epoch {epoch + 1} accuracies: \\t train: {average_train_accuracy}\\t loss: {average_train_loss}\\t')\n","        # print(f'epoch {epoch + 1} accuracies: \\t train: {average_train_accuracy}\\t valid: {average_valid_accuracy} loss: {average_train_loss}\\t')\n","        # print(f'epoch {epoch + 1} accuracies: \\t train: {average_train_accuracy}\\t valid: {average_valid_accuracy}\\t valid loss: {average_valid_loss}\\t precision: {average_precision}\\t recall: {average_recall}\\t')\n","        # dataset.shuffle()\n","\n","    # test mode\n","    # dataset.set_partition(dataset.test)\n","    model.eval()\n","    total_test_correct = 0\n","    # total_test_tp = 0\n","    # total_test_fp = 0\n","    # total_test_fn = 0\n","    count = 0\n","    for x, y in dataset.test_dataset:\n","        state = None\n","        y_h, state = model(x.to(dev), state)\n","        total_test_correct += (y_h.argmax(-1) == y.cuda()).float().mean()\n","        # total_test_tp += float((y_h.argmax(-1) == y.cuda() & (y.cuda() == 1)).float())\n","        # total_test_fp += float((y_h.argmax(-1) != y.cuda() & (y.cuda() == 0)).float())\n","        # total_test_fn += float((y_h.argmax(-1) != y.cuda() & (y.cuda() == 1)).float())\n","        count += 1\n","    average_test_accuracy = total_test_correct / count\n","    # average_precision = total_test_tp / (total_test_tp + total_test_fp)\n","    # average_recall = total_test_tp / (total_test_tp + total_test_fn)\n","\n","    print(f'test accuracy {average_test_accuracy}')\n","\n","    # return losses, (average_train_accuracy, average_valid_accuracy, average_test_accuracy)\n","    return losses, (average_train_accuracy, average_test_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SbWvcYEurRyy","executionInfo":{"status":"ok","timestamp":1622466125062,"user_tz":-480,"elapsed":149526,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"c6e16ea5-d94b-44d6-a165-3d21b8c1bb3f"},"source":["num_epochs = 20\n","batch_size = 32  # Number of hidden neurons in model\n","context_window = 1\n","k = 9\n","\n","dev = 'cuda' if torch.cuda.is_available() else 'cpu'  # If you have a GPU installed, use that, otherwise CPU\n","print(dev)\n","print('Loading data...')\n","all_files = glob.glob(\"data/sentiment/*.csv\")\n","# all_files = glob.glob(\"*.csv\")\n","data = pd.concat((pd.read_csv(f, header=None, index_col=None) for f in all_files))\n","# path = os.path.join('data', 'sentiment', 'amazon_cells_labelled.csv')\n","# data = pd.read_csv(path)\n","data.columns = ['sentence', 'label']\n","data = data.sample(frac=1, random_state=1)\n","# data = shuffle(data)\n","dataset = DataLoader(data, k=k, batch_size = batch_size, context_window=context_window, dev=dev)\n","# print(f'Data Size: {dataset.df.size()}')\n","print(\"Data Ready!\")\n","vocabulary_size = len(dataset.vocab)\n","len_seq = dataset.max_length\n","num_classes = 2\n","\n","# model = FastText(len(dataset.token_to_id)+2, num_hidden, len(dataset.class_to_id)).to(dev)\n","model = RelexNet(vocabulary_size=vocabulary_size, len_seq=len_seq, num_classes=num_classes).cuda()\n","# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n","optimizer = torch.optim.Adam(model.parameters(),lr=0.01,betas=(0.9,0.99))\n","# optimizer = torch.optim.Adam(model.parameters(),lr=0.01,betas=(0.9,0.99), weight_decay=10)\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[8 * dataset.no_batch, 14 * dataset.no_batch],gamma = 0.1, last_epoch=-1)\n","\n","losses, accuracies = train_model(dataset, model, optimizer, scheduler, num_epochs, dev=dev)\n","print(losses)\n","# torch.save(model, os.path.join('classifier.pth'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n","Loading data...\n","Max Length : 70\n","Vocab Size : 5309\n","Input Data Shape (sequence_num, sequence_len, vocab_size + 1) : torch.Size([2700, 70, 5309])\n","Input Label Shape : torch.Size([2700])\n","Input Data Shape (sequence_num, sequence_len, vocab_size + 1) : torch.Size([300, 70, 5309])\n","Input Label Shape : torch.Size([300])\n","Train Dataset Shape : torch.Size([2700, 70, 5309])\n","Test Dataset Shape : torch.Size([300, 70, 5309])\n","Data Ready!\n","1 optim: 0.01\n","epoch 1 accuracies: \t train: 0.6002451181411743\t loss: 0.679706097350401\t\n","2 optim: 0.01\n","epoch 2 accuracies: \t train: 0.6580882668495178\t loss: 0.6436182393747217\t\n","3 optim: 0.01\n","epoch 3 accuracies: \t train: 0.7025735378265381\t loss: 0.6186444002039292\t\n","4 optim: 0.01\n","epoch 4 accuracies: \t train: 0.7137255072593689\t loss: 0.5990296518101411\t\n","5 optim: 0.01\n","epoch 5 accuracies: \t train: 0.7377451062202454\t loss: 0.5820475143544814\t\n","6 optim: 0.01\n","epoch 6 accuracies: \t train: 0.7547793984413147\t loss: 0.5678626200732063\t\n","7 optim: 0.01\n","epoch 7 accuracies: \t train: 0.7649510502815247\t loss: 0.5552046242882224\t\n","8 optim: 0.001\n","epoch 8 accuracies: \t train: 0.7604166269302368\t loss: 0.5531739585539874\t\n","9 optim: 0.001\n","epoch 9 accuracies: \t train: 0.7604166269302368\t loss: 0.5519051365992602\t\n","10 optim: 0.001\n","epoch 10 accuracies: \t train: 0.782598078250885\t loss: 0.5401689392678878\t\n","11 optim: 0.001\n","epoch 11 accuracies: \t train: 0.7779411673545837\t loss: 0.5433129563051111\t\n","12 optim: 0.001\n","epoch 12 accuracies: \t train: 0.7767157554626465\t loss: 0.5357155859470367\t\n","13 optim: 0.001\n","epoch 13 accuracies: \t train: 0.7797794342041016\t loss: 0.5391264631467707\t\n","14 optim: 0.0001\n","epoch 14 accuracies: \t train: 0.7741422057151794\t loss: 0.5398420239196104\t\n","15 optim: 0.0001\n","epoch 15 accuracies: \t train: 0.7865195870399475\t loss: 0.5342893358539132\t\n","16 optim: 0.0001\n","epoch 16 accuracies: \t train: 0.7811275124549866\t loss: 0.537464943002252\t\n","17 optim: 0.0001\n","epoch 17 accuracies: \t train: 0.7688725590705872\t loss: 0.5422898583552417\t\n","18 optim: 0.0001\n","epoch 18 accuracies: \t train: 0.772549033164978\t loss: 0.5418151497840882\t\n","19 optim: 0.0001\n","epoch 19 accuracies: \t train: 0.785171627998352\t loss: 0.5365450087715598\t\n","20 optim: 0.0001\n","epoch 20 accuracies: \t train: 0.7724264860153198\t loss: 0.539515587161569\t\n","test accuracy 0.7791666388511658\n","[0.679706097350401, 0.6436182393747217, 0.6186444002039292, 0.5990296518101411, 0.5820475143544814, 0.5678626200732063, 0.5552046242882224, 0.5531739585539874, 0.5519051365992602, 0.5401689392678878, 0.5433129563051111, 0.5357155859470367, 0.5391264631467707, 0.5398420239196104, 0.5342893358539132, 0.537464943002252, 0.5422898583552417, 0.5418151497840882, 0.5365450087715598, 0.539515587161569]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xzzcdPQuRcyw"},"source":[""],"execution_count":null,"outputs":[]}]}