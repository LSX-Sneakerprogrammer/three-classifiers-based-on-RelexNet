{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"relexnet with modifier final model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOHMSO9Fs5zw54Oe5XdN9Va"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"Rq-8cdE6uSVj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622444106098,"user_tz":-480,"elapsed":50221,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"b24af1db-485a-454b-ee0b-93ed2460d83d"},"source":["# Use in the google colab to connect the google cloud in order to get the dataset\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","··········\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPU2-Bjaw3if","executionInfo":{"status":"ok","timestamp":1622444111777,"user_tz":-480,"elapsed":1108,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"a4498631-b883-470d-cdb5-2d894ec94ad5"},"source":["# Use in google colab in order to get information about GPU\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon May 31 06:55:10 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bWU91uoOxa0F"},"source":["# Use in google colab in order to get the root path\n","!mkdir -p drive\n","!google-drive-ocamlfuse -o nonempty drive\n","import os\n","import sys\n","os.chdir('drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"keypfrnLhTp5"},"source":["import nltk\n","from functools import lru_cache\n","import re\n","import string\n","import numpy as np\n","import pandas as pd\n","import torch\n","from collections import Counter, defaultdict\n","from sklearn.preprocessing import OneHotEncoder\n","import torch.utils.data as Data\n","import torch.nn.functional as F\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import os\n","import glob\n","from sklearn.utils import shuffle\n","import copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"knN_KDWrqNHX","executionInfo":{"status":"ok","timestamp":1622444118824,"user_tz":-480,"elapsed":7,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"2a0669e0-3d2b-44b9-a2af-d6f622212d3b"},"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    # print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print(torch.cuda.device_count())\n","    print('Device name:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\n","Device name: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F36OHIItkZpx"},"source":["class Modifiers:\n","    def __init__(self):\n","        C_INCR = 0.733\n","        B_INCR = 0.293\n","        B_DECR = -0.293\n","\n","        N_SCALAR = -0.74\n","        self.NEGATE = \\\n","            [\"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\", \"didnt\", \"doesnt\",\n","             \"ain't\", \"aren't\", \"can't\", \"couldn't\", \"daren't\", \"didn't\", \"doesn't\",\n","             \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\", \"neither\",\n","             \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\",\n","             \"neednt\", \"needn't\", \"never\", \"none\", \"nope\", \"nor\", \"not\", \"nothing\", \"nowhere\",\n","             \"oughtnt\", \"shant\", \"shouldnt\", \"uhuh\", \"wasnt\", \"werent\",\n","             \"oughtn't\", \"shan't\", \"shouldn't\", \"uh-uh\", \"wasn't\", \"weren't\",\n","             \"without\", \"wont\", \"wouldnt\", \"won't\", \"wouldn't\", \"rarely\", \"seldom\", \"despite\"]\n","\n","        # booster/dampener 'intensifiers' or 'degree adverbs'\n","        # \n","\n","        self.BOOSTER_DICT = \\\n","            {\"absolutely\": B_INCR, \"amazingly\": B_INCR, \"awfully\": B_INCR, \"completely\": B_INCR, \"considerably\": B_INCR,\n","             \"decidedly\": B_INCR, \"deeply\": B_INCR, \"effing\": B_INCR, \"enormously\": B_INCR,\n","             \"entirely\": B_INCR, \"especially\": B_INCR, \"exceptionally\": B_INCR, \"extremely\": B_INCR,\n","             \"fabulously\": B_INCR, \"flipping\": B_INCR, \"flippin\": B_INCR,\n","             \"fricking\": B_INCR, \"frickin\": B_INCR, \"frigging\": B_INCR, \"friggin\": B_INCR, \"fully\": B_INCR,\n","             \"fucking\": B_INCR,\n","             \"greatly\": B_INCR, \"hella\": B_INCR, \"highly\": B_INCR, \"hugely\": B_INCR, \"incredibly\": B_INCR,\n","             \"intensely\": B_INCR, \"majorly\": B_INCR, \"more\": B_INCR, \"most\": B_INCR, \"particularly\": B_INCR,\n","             \"purely\": B_INCR, \"quite\": B_INCR, \"really\": B_INCR, \"remarkably\": B_INCR,\n","             \"so\": B_INCR, \"substantially\": B_INCR,\n","             \"thoroughly\": B_INCR, \"totally\": B_INCR, \"tremendously\": B_INCR,\n","             \"uber\": B_INCR, \"unbelievably\": B_INCR, \"unusually\": B_INCR, \"utterly\": B_INCR,\n","             \"very\": B_INCR,\n","             \"almost\": B_DECR, \"barely\": B_DECR, \"hardly\": B_DECR, \"just enough\": B_DECR,\n","             \"kind of\": B_DECR, \"kinda\": B_DECR, \"kindof\": B_DECR, \"kind-of\": B_DECR,\n","             \"less\": B_DECR, \"little\": B_DECR, \"marginally\": B_DECR, \"occasionally\": B_DECR, \"partly\": B_DECR,\n","             \"scarcely\": B_DECR, \"slightly\": B_DECR, \"somewhat\": B_DECR,\n","             \"sort of\": B_DECR, \"sorta\": B_DECR, \"sortof\": B_DECR, \"sort-of\": B_DECR}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"by-7uhU7n1cs"},"source":["class Preprocessor:\n","    def clean_text(self, text):\n","        # '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n","        # make text lowercase\n","        text1 = text.lower()\n","        # remove square brackets\n","        text1 = re.sub('\\[.*?\\]', '', text1)\n","        #remove <>\n","        text1 = re.sub('<.*?>+', '', text1)\n","        text1 = re.sub('\\(.*?\\)', ' ', text1)\n","        text1 = re.sub('\\{.*?\\}', ' ', text1)\n","        # remove links\n","        text1 = re.sub('https?://\\S+|www\\.\\S+', ' ', text1)\n","        # remove punctuation\n","        text1 = re.sub('[%s]' % re.escape(string.punctuation), '', text1)\n","        # remove \\n\n","        # text = re.sub('\\n', '', text)\n","        # remove numbers\n","        text = re.sub('\\w*\\d\\w*', '', text)\n","        return text1\n","\n","    def __init__(self):\n","        self.stem = lru_cache(maxsize=10000)(nltk.stem.SnowballStemmer('english').stem)\n","        # self.stopwords = stopwords.words('english')\n","        self.tokenize = nltk.tokenize.TreebankWordTokenizer().tokenize\n","\n","    def __call__(self, text):\n","        text1 = self.clean_text(text)\n","        tokens = self.tokenize(text1)\n","        # tokens = [token for token in tokens if token not in self.stopwords]\n","        # tokens = [self.stem(token) for token in tokens]\n","\n","        return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jxP_rB3xoeLK"},"source":["\n","class DataLoader:\n","    def __init__(self, data, batch_size, k, context_window = 1, preprocessor=Preprocessor(), enc_tokens = OneHotEncoder(), enc_modifiers = OneHotEncoder(), modifier = Modifiers(), dev = 'cpu'):\n","        self.df = data\n","        self.dev = dev\n","        self.batch_size = batch_size\n","        self.context_window = context_window\n","        self.modifiers = modifier.BOOSTER_DICT.keys()\n","        self.enc_modifiers = enc_modifiers\n","        # self.vocab_frequency = 5\n","        self.padding_length = 70\n","        self.fold_num = 10\n","        # self.first_sentence = 128\n","        # self.second_sentence = self.padding_length - self.first_sentence\n","        self.count = 0\n","\n","\n","        self.apply_preprocessor(preprocessor)\n","        enc_tokens.fit(self.vocab)\n","        self.enc_modifiers = enc_modifiers\n","        self.enc_modifiers.fit(self.modifier_id_to_fit)\n","        self.split(0.9, 0.1)\n","\n","        train_num = len(self.train)\n","        if train_num % self.batch_size == 0:\n","            self.no_batch = train_num / self.batch_size\n","        else:\n","            self.no_batch = int(train_num / self.batch_size) + 1\n","\n","        trainX, trainY = self.build_training_data(enc_tokens, self.train)\n","        testX, testY = self.build_training_data(enc_tokens, self.test)\n","        print(f'Train Dataset Shape : {trainX.shape}')\n","        print(f'Test Dataset Shape : {testX.shape}')\n","        print(f'Next Modifier : {self.count}')\n","        self.train_dataset = self.get_batch(trainX, trainY)\n","        self.test_dataset = self.get_batch(testX, testY)\n","\n","\n","\n","    def get_batch(self, X, Y):\n","        dataset = Data.TensorDataset(X, Y)\n","        loader = Data.DataLoader(\n","            dataset=dataset,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            # num_workers=2,\n","        )\n","        return loader\n","\n","\n","    def remove_low_frequency(self, list):\n","        new_list = []\n","        for x in list:\n","            if x in self.token_to_count.keys():\n","                new_list.append(x)\n","        return new_list\n","\n","\n","    def apply_preprocessor(self, preprocessor):\n","        self.df['tokens'] = [preprocessor(s) for s in self.df['sentence']]\n","        self.df['tokens'] = [x[:self.padding_length]  if len(x) > self.padding_length else x for x in self.df['tokens']]\n","\n","        # for index, row in self.df.iterrows():\n","        #     if len(row['tokens']) > self.max_length:\n","        #         row[toke]\n","\n","        ######## Changed part for negatives ###########\n","        self.token_to_count = Counter([x for l in self.df['tokens'] for x in l if x not in self.modifiers])\n","        self.modifiers_to_count = Counter([x for l in self.df['tokens'] for x in l if x in self.modifiers])\n","        ##############      End       #################\n","\n","        # tmp_token_to_count = self.token_to_count.copy()\n","        # for index, value in tmp_token_to_count.items():\n","        #     if value <= self.vocab_frequency:\n","        #         self.token_to_count.pop(index)\n","        # self.df['tokens'] = [self.remove_low_frequency(x) for x in self.df['tokens']]\n","        self.max_length = self.get_max_length()\n","        print(f'Max Length : {self.max_length}')\n","\n","        ######## Changed part for negatives ###########\n","        self.vocab = list([[term] for term in self.token_to_count.keys()])\n","        self.modifier_vocab = list([[term] for term in self.modifiers_to_count.keys()])\n","        self.modifier_token_to_id = {self.modifier_vocab[i][0]: i + 1 for i in range(len(self.modifier_vocab))}\n","        self.modifier_id_to_fit = list([[term] for term in self.modifier_token_to_id.values()])\n","        ##############      End       #################\n","\n","        print(f'Vocab Size : {len(self.vocab)}')\n","        print(f'Modifier Size : {len(self.modifier_vocab)}')\n","        # print(self.token_to_count)\n","\n","    def get_max_length(self):\n","        max_length = 0\n","        for index, row in self.df.iterrows():\n","            ######## Changed part for negatives ###########\n","            token_list = [x for x in row['tokens'] if x not in self.modifiers]\n","            ##############      End       #################\n","            tmp_length = len(token_list)\n","            if tmp_length > max_length:\n","                max_length = tmp_length\n","        return max_length\n","\n","    def k_fold_partition(self, fold_num = 10):\n","        batch_size = int(len(self.train) / fold_num) # the number of data for each fold\n","        remain_num = len(self.train) - batch_size * fold_num # the remain data after partition\n","        self.fold_data = []\n","        fold_batch_list = [] # Average the remaining data to the folds\n","        for fold in range(fold_num):\n","          if remain_num > 0:\n","            remain_num -= 1\n","            fold_batch_list.append(batch_size + 1)\n","          else:\n","            fold_batch_list.append(batch_size)\n","        fold_index = 0 # The starting position of each division data\n","        for fold in range(fold_num):\n","          fold_texts = [fold_index, fold_index + fold_batch_list[fold]]\n","          self.fold_data.append(fold_texts)\n","          # print(f'fold_data : {fold_batch_list[fold]}')\n","          # print(f'fold_data type : {type(fold_batch_list[fold])}')\n","          # print(f'index type : {type(fold_index)}')\n","          fold_index = fold_index + fold_batch_list[fold]\n","\n","\n","    def k_fold_split(self, k):\n","        print(f'K : {k}, fold_data[k] : {self.fold_data[k]}')\n","        validation = self.train.iloc[self.fold_data[k][0]: self.fold_data[k][1]]\n","        train = self.train.iloc[0: self.fold_data[k][0]].append(self.train.iloc[self.fold_data[k][1]:])\n","        train_num = len(self.train) - (self.fold_data[k][1] - self.fold_data[k][0])\n","        if train_num % self.batch_size == 0:\n","            self.no_batch = train_num / self.batch_size\n","        else:\n","            self.no_batch = int(train_num / self.batch_size) + 1\n","        print(f' index : {self.no_batch}')\n","        return train, validation\n","\n","\n","\n","    def split(self, train, test):\n","        index = int(train * len(self.df))\n","        self.train = self.df.iloc[0:index]\n","        self.test = self.df.iloc[index:]\n","        # if self.train_index % self.batch_size == 0:\n","        #     self.no_batch = self.train_index / self.batch_size\n","        # else:\n","        #     self.no_batch = int(self.train_index / self.batch_size) + 1\n","        # print(f' index : {self.no_batch}')\n","\n","    def build_training_data(self, enc, df):\n","        X = []\n","        Y = []\n","        for index, row in df.iterrows():\n","            # build modifiers\n","            np_modifier = np.zeros(len(row['tokens']))\n","            for index, value in enumerate(row['tokens']):\n","                # label the word influenced by modifiers\n","                if value in self.modifiers:\n","                    id = self.modifier_token_to_id[value]\n","                    np_modifier[index] = -1\n","                    for i in range(1, self.context_window + 1):\n","                        if index - i > 0:\n","                            np_modifier[index - i] = id\n","                            if row['tokens'][index - i] in self.modifiers:\n","                              self.count += 1\n","                        if index + i < len(row['tokens']):\n","                            np_modifier[index + i] = id\n","                            if row['tokens'][index + i] in self.modifiers:\n","                              self.count += 1\n","                    # np_modifier[index - self.context_window] = id\n","                    # np_modifier[index] = -1\n","                    # if (index + self.context_window) < len(row['tokens']):\n","                    #     np_modifier[index + self.context_window] = id\n","\n","            ######## Changed part for negatives ###########\n","            # delete modifier itself\n","            deleted_index = [i for i in range(len(np_modifier)) if np_modifier[i] == -1]\n","            np_modifier = np.delete(np_modifier, deleted_index)\n","\n","\n","            tmp = [enc.transform([[t]]).toarray()[0] for t in row['tokens'] if t not in self.modifiers]\n","            for i in range(len(tmp)):\n","                tmp[i] = np.append(tmp[i], np_modifier[i])\n","            if len(tmp) < self.max_length:\n","                pad_length = self.max_length - len(tmp)\n","                for i in range(pad_length):\n","                    tmp.append(np.append(np.zeros(len(self.vocab)), -1))\n","            ##############      End       #################\n","            X.append(tmp)\n","            Y.append(row['label'])\n","        X = np.array(X)\n","        Y = np.array(Y)\n","        X = torch.from_numpy(X).float()\n","        Y = torch.from_numpy(Y).long()\n","        print(f'Input Data Shape (sequence_num, sequence_len, vocab_size + 1) : {X.shape}')\n","        print(f'Input Label Shape : {Y.shape}')\n","        return X, Y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gOBWpAvWrAdh"},"source":["class RelexNet(nn.Module):\n","    #Single step RNN.\n","    #input_size is char_vacab_size=26,hidden_size is number of hidden neurons，output_size is number of categories\n","    def __init__(self, vocabulary_size, modifier_size, len_seq, num_classes, enc):\n","        super(RelexNet, self).__init__()\n","        self.no_modifiers = np.zeros(modifier_size)\n","        self.num_classes = num_classes\n","        self.L = nn.Linear(vocabulary_size, num_classes)\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.M = nn.Linear(modifier_size, 1).cuda()\n","        # self.B = nn.Linear(len_seq, len_seq)\n","        self.enc = enc\n","        self.softmax = nn.Softmax(dim=1)\n","\n","\n","    def handle_modifier(self, modifier_ids, batch):\n","        # modifier_id = modifier_ids.cpu()\n","        modifier = []\n","        influence_flag = []\n","        add = 0.5 * Variable(torch.ones(batch, 1))\n","        for i in range(batch):\n","            if modifier_ids[i] == 0:\n","                modifier.append(self.no_modifiers)\n","                influence_flag.append(0)\n","                add[i] = 1\n","            elif modifier_ids[i] == -1:\n","                modifier.append(self.no_modifiers)\n","                influence_flag.append(0)\n","                add[i] = 0\n","            else:\n","                # print(modifier_ids[i])\n","                modifier.append(self.enc.transform([[modifier_ids[i].cpu()]]).toarray()[0])\n","                influence_flag.append(1)\n","        modifier = torch.tensor(modifier).float().cuda()\n","        influence_flag = torch.tensor(influence_flag).float()\n","        influence_flag = influence_flag.reshape(-1, 1).cuda()\n","        add = add.cuda()\n","        return modifier, influence_flag, add\n","\n","\n","\n","    def forward(self, input, B_layer):\n","        # X.shape = (batch, seq_len, vocab_size)\n","        T = input.shape[1]\n","        batch = input.shape[0]\n","        predict_y = Variable(torch.zeros(batch, self.num_classes))\n","\n","        if B_layer is None:\n","            B_layer = Variable(torch.zeros(batch, self.num_classes)).cuda()\n","\n","        for t in range(T):\n","            tmp = input[:, t, :-1]\n","            modifier_ids = input[:, t, -1]\n","            modifier, influence_flag, add = self.handle_modifier(modifier_ids, batch)\n","\n","            L_onestep = self.L(tmp)\n","            L_onestep = self.dropout(L_onestep)\n","            # L_onestep = torch.sigmoid(L_onestep)\n","            # L_onestep = MyReLU_PLUS.apply(L_onestep)\n","            L_onestep = F.relu6(L_onestep)\n","            modifier_score = torch.sigmoid(self.M(modifier))\n","            modifier_score = modifier_score * influence_flag\n","            modifier_score = modifier_score + add\n","            # L_onestep = L_onestep + modifier_score\n","\n","            L_onestep = L_onestep * modifier_score\n","            # L_onestep = L_onestep * negative_score\n","\n","            B_layer = torch.add(B_layer, L_onestep)\n","            # print(B_layer)\n","\n","            if self.num_classes == 1:\n","                predict_y[t] = F.sigmoid(B_layer)\n","            else:\n","                predict_y = self.softmax(B_layer)\n","\n","        return predict_y, B_layer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rE53K7W8sP4K"},"source":["def train_model(dataset, model, optimizer, scheduler, num_epochs, dev):\n","    losses = []\n","    for epoch in range(num_epochs):\n","        # training mode\n","        # dataset.set_partition(dataset.train)\n","        model.train()\n","        total_train_loss = 0\n","        total_train_correct = 0\n","        count = 0\n","        for x, y in dataset.train_dataset:\n","            # for every batch in the training dataset perform one update step of the optimizer.\n","            state = None\n","            model.zero_grad()\n","            y_h, state = model(x.to(dev), state)\n","            loss = F.cross_entropy(y_h, y.to(dev))\n","            optimizer.zero_grad()\n","            # scheduler.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            # print('{} optim: {}'.format(epoch, optimizer.param_groups[0]['lr']))\n","            scheduler.step()\n","            # print('{} scheduler: {}'.format(epoch, scheduler.get_lr()[0]))\n","            total_train_loss += loss.item()\n","            total_train_correct += (y_h.argmax(-1) == y.cuda()).float().mean()\n","            count += 1\n","        average_train_loss = total_train_loss / count\n","        average_train_accuracy = total_train_correct / count\n","        print('{} optim: {}'.format(epoch + 1, optimizer.param_groups[0]['lr']))\n","        # print('{} optim: {}'.format(epoch, optimizer.param_groups[0]['lr']))\n","        # print('{} scheduler: {}'.format(epoch, scheduler.get_lr()[0]))\n","        losses.append(average_train_loss)\n","\n","        print(f'epoch {epoch + 1} accuracies: \\t train: {average_train_accuracy}\\t loss: {average_train_loss}\\t')\n","        # print(f'epoch {epoch + 1} accuracies: \\t train: {average_train_accuracy}\\t valid: {average_valid_accuracy}\\t valid loss: {average_valid_loss}\\t precision: {average_precision}\\t recall: {average_recall}\\t')\n","        # dataset.shuffle()\n","\n","    # test mode\n","    # dataset.set_partition(dataset.test)\n","    model.eval()\n","    total_test_correct = 0\n","    # total_test_tp = 0\n","    # total_test_fp = 0\n","    # total_test_fn = 0\n","    count = 0\n","    for x, y in dataset.test_dataset:\n","        state = None\n","        y_h, state = model(x.to(dev), state)\n","        total_test_correct += (y_h.argmax(-1) == y.cuda()).float().mean()\n","        # total_test_tp += float((y_h.argmax(-1) == y.cuda() & (y.cuda() == 1)).float())\n","        # total_test_fp += float((y_h.argmax(-1) != y.cuda() & (y.cuda() == 0)).float())\n","        # total_test_fn += float((y_h.argmax(-1) != y.cuda() & (y.cuda() == 1)).float())\n","        count += 1\n","    average_test_accuracy = total_test_correct / count\n","    # average_precision = total_test_tp / (total_test_tp + total_test_fp)\n","    # average_recall = total_test_tp / (total_test_tp + total_test_fn)\n","\n","    # print(f'test accuracy {average_test_accuracy} precision {average_precision} recall {average_recall}')\n","    print(f'test accuracy {average_test_accuracy}')\n","\n","    return losses, (average_train_accuracy, average_test_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SbWvcYEurRyy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622444751579,"user_tz":-480,"elapsed":416329,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"2cff96b9-7b98-4749-93db-bd10ce6c0e28"},"source":["num_epochs = 20\n","batch_size = 32  # Number of hidden neurons in model\n","context_window = 1\n","k = 9\n","\n","dev = 'cuda' if torch.cuda.is_available() else 'cpu'  # If you have a GPU installed, use that, otherwise CPU\n","print(dev)\n","print('Loading data...')\n","all_files = glob.glob(\"data/sentiment/*.csv\")\n","# all_files = glob.glob(\"*.csv\")\n","data = pd.concat((pd.read_csv(f, header=None, index_col=None) for f in all_files))\n","# path = os.path.join('data', 'sentiment', 'amazon_cells_labelled.csv')\n","# data = pd.read_csv(path)\n","data.columns = ['sentence', 'label']\n","data = data.sample(frac=1, random_state=1)\n","# data = shuffle(data)\n","dataset = DataLoader(data, k=k, batch_size = batch_size, context_window=context_window, dev=dev)\n","# print(f'Data Size: {dataset.df.size()}')\n","print(\"Data Ready!\")\n","vocabulary_size = len(dataset.vocab)\n","len_seq = dataset.max_length\n","num_classes = 2\n","\n","# model = FastText(len(dataset.token_to_id)+2, num_hidden, len(dataset.class_to_id)).to(dev)\n","model = RelexNet(vocabulary_size=vocabulary_size, enc=dataset.enc_modifiers, modifier_size=len(dataset.modifier_vocab),len_seq=len_seq, num_classes=num_classes).cuda()\n","# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n","optimizer = torch.optim.Adam(model.parameters(),lr=0.01,betas=(0.9,0.99))\n","# optimizer = torch.optim.Adam(model.parameters(),lr=0.01,betas=(0.9,0.99), weight_decay=10)\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[8 * dataset.no_batch, 14 * dataset.no_batch],gamma = 0.1, last_epoch=-1)\n","\n","losses, accuracies = train_model(dataset, model, optimizer, scheduler, num_epochs, dev=dev)\n","print(losses)\n","# torch.save(model, os.path.join('./relexnet_model/classifier_M9.pth'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n","Loading data...\n","Max Length : 68\n","Vocab Size : 5275\n","Modifier Size : 34\n","Input Data Shape (sequence_num, sequence_len, vocab_size + 1) : torch.Size([2700, 68, 5276])\n","Input Label Shape : torch.Size([2700])\n","Input Data Shape (sequence_num, sequence_len, vocab_size + 1) : torch.Size([300, 68, 5276])\n","Input Label Shape : torch.Size([300])\n","Train Dataset Shape : torch.Size([2700, 68, 5276])\n","Test Dataset Shape : torch.Size([300, 68, 5276])\n","Next Modifier : 38\n","Data Ready!\n","1 optim: 0.01\n","epoch 1 accuracies: \t train: 0.5841912031173706\t loss: 0.6729133816326366\t\n","2 optim: 0.01\n","epoch 2 accuracies: \t train: 0.7332108020782471\t loss: 0.5983270813437069\t\n","3 optim: 0.01\n","epoch 3 accuracies: \t train: 0.7901960611343384\t loss: 0.5491945196600522\t\n","4 optim: 0.01\n","epoch 4 accuracies: \t train: 0.8089460730552673\t loss: 0.5244633271413691\t\n","5 optim: 0.01\n","epoch 5 accuracies: \t train: 0.8251225352287292\t loss: 0.5006516621393315\t\n","6 optim: 0.01\n","epoch 6 accuracies: \t train: 0.8327205777168274\t loss: 0.49386078540016626\t\n","7 optim: 0.01\n","epoch 7 accuracies: \t train: 0.8493872284889221\t loss: 0.47960001861347873\t\n","8 optim: 0.001\n","epoch 8 accuracies: \t train: 0.8605392575263977\t loss: 0.4681854816044078\t\n","9 optim: 0.001\n","epoch 9 accuracies: \t train: 0.8535539507865906\t loss: 0.4645388441927293\t\n","10 optim: 0.001\n","epoch 10 accuracies: \t train: 0.8519607782363892\t loss: 0.46781222224235536\t\n","11 optim: 0.001\n","epoch 11 accuracies: \t train: 0.863725483417511\t loss: 0.46277722365715923\t\n","12 optim: 0.001\n","epoch 12 accuracies: \t train: 0.8658088445663452\t loss: 0.46041780149235445\t\n","13 optim: 0.001\n","epoch 13 accuracies: \t train: 0.8675245642662048\t loss: 0.46030719806166254\t\n","14 optim: 0.0001\n","epoch 14 accuracies: \t train: 0.8573529720306396\t loss: 0.46359291988260604\t\n","15 optim: 0.0001\n","epoch 15 accuracies: \t train: 0.8564951419830322\t loss: 0.4643239550730761\t\n","16 optim: 0.0001\n","epoch 16 accuracies: \t train: 0.8623775243759155\t loss: 0.46061586702571194\t\n","17 optim: 0.0001\n","epoch 17 accuracies: \t train: 0.8693627715110779\t loss: 0.4571906201979693\t\n","18 optim: 0.0001\n","epoch 18 accuracies: \t train: 0.8616421818733215\t loss: 0.4614725540666019\t\n","19 optim: 0.0001\n","epoch 19 accuracies: \t train: 0.8642157316207886\t loss: 0.4538688393200145\t\n","20 optim: 0.0001\n","epoch 20 accuracies: \t train: 0.8550245761871338\t loss: 0.46334719026789944\t\n","test accuracy 0.8458333015441895\n","[0.6729133816326366, 0.5983270813437069, 0.5491945196600522, 0.5244633271413691, 0.5006516621393315, 0.49386078540016626, 0.47960001861347873, 0.4681854816044078, 0.4645388441927293, 0.46781222224235536, 0.46277722365715923, 0.46041780149235445, 0.46030719806166254, 0.46359291988260604, 0.4643239550730761, 0.46061586702571194, 0.4571906201979693, 0.4614725540666019, 0.4538688393200145, 0.46334719026789944]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xzzcdPQuRcyw"},"source":[""],"execution_count":null,"outputs":[]}]}