{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"relexnet negative final model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOPUeADVvshYvrFspVC/sTH"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"Rq-8cdE6uSVj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622445162228,"user_tz":-480,"elapsed":96815,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"c5ce2fc2-c0ba-4a1b-ffda-61f20057ae01"},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 160706 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.26-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPU2-Bjaw3if","executionInfo":{"status":"ok","timestamp":1622445191869,"user_tz":-480,"elapsed":647,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"0381dcf5-280e-426f-944c-8eca521ad03c"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon May 31 07:13:10 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bWU91uoOxa0F"},"source":["!mkdir -p drive\n","!google-drive-ocamlfuse -o nonempty drive\n","import os\n","import sys\n","os.chdir('drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"keypfrnLhTp5"},"source":["import nltk\n","from functools import lru_cache\n","import re\n","import string\n","import numpy as np\n","import pandas as pd\n","import torch\n","from collections import Counter, defaultdict\n","from sklearn.preprocessing import OneHotEncoder\n","import torch.utils.data as Data\n","import torch.nn.functional as F\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import os\n","import glob\n","from sklearn.utils import shuffle\n","import copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"knN_KDWrqNHX","executionInfo":{"status":"ok","timestamp":1622445200548,"user_tz":-480,"elapsed":14,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"f5731f6c-72f8-46df-a2e0-08a9e8d43a2c"},"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    # print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print(torch.cuda.device_count())\n","    print('Device name:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\n","Device name: Tesla V100-SXM2-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCiTJxaMqlt-","executionInfo":{"status":"ok","timestamp":1622445200548,"user_tz":-480,"elapsed":12,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"f11d53ce-cba9-4025-8553-24b9b46c5597"},"source":["!/opt/bin/nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon May 31 07:13:20 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    24W / 300W |      2MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F36OHIItkZpx"},"source":["class Modifiers:\n","    def __init__(self):\n","        C_INCR = 0.733\n","        B_INCR = 0.293\n","        B_DECR = -0.293\n","\n","        N_SCALAR = -0.74\n","        self.NEGATE = \\\n","            [\"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\", \"didnt\", \"doesnt\",\n","             \"ain't\", \"aren't\", \"can't\", \"couldn't\", \"daren't\", \"didn't\", \"doesn't\",\n","             \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\", \"neither\",\n","             \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\",\n","             \"neednt\", \"needn't\", \"never\", \"none\", \"nope\", \"nor\", \"not\", \"nothing\", \"nowhere\",\n","             \"oughtnt\", \"shant\", \"shouldnt\", \"uhuh\", \"wasnt\", \"werent\",\n","             \"oughtn't\", \"shan't\", \"shouldn't\", \"uh-uh\", \"wasn't\", \"weren't\",\n","             \"without\", \"wont\", \"wouldnt\", \"won't\", \"wouldn't\", \"rarely\", \"seldom\", \"despite\"]\n","\n","        # booster/dampener 'intensifiers' or 'degree adverbs'\n","        # \n","\n","        self.BOOSTER_DICT = \\\n","            {\"absolutely\": B_INCR, \"amazingly\": B_INCR, \"awfully\": B_INCR, \"completely\": B_INCR, \"considerably\": B_INCR,\n","             \"decidedly\": B_INCR, \"deeply\": B_INCR, \"effing\": B_INCR, \"enormously\": B_INCR,\n","             \"entirely\": B_INCR, \"especially\": B_INCR, \"exceptionally\": B_INCR, \"extremely\": B_INCR,\n","             \"fabulously\": B_INCR, \"flipping\": B_INCR, \"flippin\": B_INCR,\n","             \"fricking\": B_INCR, \"frickin\": B_INCR, \"frigging\": B_INCR, \"friggin\": B_INCR, \"fully\": B_INCR,\n","             \"fucking\": B_INCR,\n","             \"greatly\": B_INCR, \"hella\": B_INCR, \"highly\": B_INCR, \"hugely\": B_INCR, \"incredibly\": B_INCR,\n","             \"intensely\": B_INCR, \"majorly\": B_INCR, \"more\": B_INCR, \"most\": B_INCR, \"particularly\": B_INCR,\n","             \"purely\": B_INCR, \"quite\": B_INCR, \"really\": B_INCR, \"remarkably\": B_INCR,\n","             \"so\": B_INCR, \"substantially\": B_INCR,\n","             \"thoroughly\": B_INCR, \"totally\": B_INCR, \"tremendously\": B_INCR,\n","             \"uber\": B_INCR, \"unbelievably\": B_INCR, \"unusually\": B_INCR, \"utterly\": B_INCR,\n","             \"very\": B_INCR,\n","             \"almost\": B_DECR, \"barely\": B_DECR, \"hardly\": B_DECR, \"just enough\": B_DECR,\n","             \"kind of\": B_DECR, \"kinda\": B_DECR, \"kindof\": B_DECR, \"kind-of\": B_DECR,\n","             \"less\": B_DECR, \"little\": B_DECR, \"marginally\": B_DECR, \"occasionally\": B_DECR, \"partly\": B_DECR,\n","             \"scarcely\": B_DECR, \"slightly\": B_DECR, \"somewhat\": B_DECR,\n","             \"sort of\": B_DECR, \"sorta\": B_DECR, \"sortof\": B_DECR, \"sort-of\": B_DECR}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"by-7uhU7n1cs"},"source":["class Preprocessor:\n","    def clean_text(self, text):\n","        # '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n","        # make text lowercase\n","        text1 = text.lower()\n","        # remove square brackets\n","        text1 = re.sub('\\[.*?\\]', '', text1)\n","        #remove <>\n","        text1 = re.sub('<.*?>+', '', text1)\n","        text1 = re.sub('\\(.*?\\)', ' ', text1)\n","        text1 = re.sub('\\{.*?\\}', ' ', text1)\n","        # remove links\n","        text1 = re.sub('https?://\\S+|www\\.\\S+', ' ', text1)\n","        # remove punctuation\n","        text1 = re.sub('[%s]' % re.escape(string.punctuation), '', text1)\n","        # remove \\n\n","        # text = re.sub('\\n', '', text)\n","        # remove numbers\n","        text = re.sub('\\w*\\d\\w*', '', text)\n","        return text1\n","\n","    def __init__(self):\n","        self.stem = lru_cache(maxsize=10000)(nltk.stem.SnowballStemmer('english').stem)\n","        # self.stopwords = stopwords.words('english')\n","        self.tokenize = nltk.tokenize.TreebankWordTokenizer().tokenize\n","\n","    def __call__(self, text):\n","        text1 = self.clean_text(text)\n","        tokens = self.tokenize(text1)\n","        # tokens = [token for token in tokens if token not in self.stopwords]\n","        # tokens = [self.stem(token) for token in tokens]\n","\n","        return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jxP_rB3xoeLK"},"source":["\n","class DataLoader:\n","    def __init__(self, data, batch_size, k, context_window = 1, preprocessor=Preprocessor(), enc_tokens = OneHotEncoder(), enc_modifiers = OneHotEncoder(), modifier = Modifiers(), dev = 'cpu'):\n","        self.df = data\n","        self.dev = dev\n","        self.batch_size = batch_size\n","        self.context_window = context_window\n","        self.modifiers = modifier.BOOSTER_DICT.keys()\n","        self.enc_modifiers = enc_modifiers\n","        # self.vocab_frequency = 5\n","        self.padding_length = 75\n","        self.fold_num = 10\n","        self.negatives = modifier.NEGATE\n","        # self.first_sentence = 128\n","        # self.second_sentence = self.padding_length - self.first_sentence\n","\n","\n","        self.apply_preprocessor(preprocessor)\n","        enc_tokens.fit(self.vocab)\n","        self.enc_modifiers = enc_modifiers\n","        self.enc_modifiers.fit(self.modifier_id_to_fit)\n","        # ######## Changed part for negatives ###########\n","        # self.enc_negatives = enc_negative\n","        # self.enc_negatives.fit(self.negative_id_to_fit)\n","        # ##############      End       #################\n","        self.split(0.9, 0.1)\n","        train_num = len(self.train)\n","        if train_num % self.batch_size == 0:\n","            self.no_batch = train_num / self.batch_size\n","        else:\n","            self.no_batch = int(train_num / self.batch_size) + 1\n","\n","        trainX, trainY = self.build_training_data(enc_tokens, self.train)\n","        testX, testY = self.build_training_data(enc_tokens, self.test)\n","        print(f'Train Dataset Shape : {trainX.shape}')\n","        print(f'Test Dataset Shape : {testX.shape}')\n","        self.train_dataset = self.get_batch(trainX, trainY)\n","        self.test_dataset = self.get_batch(testX, testY)\n","\n","\n","\n","    def get_batch(self, X, Y):\n","        dataset = Data.TensorDataset(X, Y)\n","        loader = Data.DataLoader(\n","            dataset=dataset,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            # num_workers=2,\n","        )\n","        return loader\n","\n","\n","    def remove_low_frequency(self, list):\n","        new_list = []\n","        for x in list:\n","            if x in self.token_to_count.keys():\n","                new_list.append(x)\n","        return new_list\n","\n","\n","    def apply_preprocessor(self, preprocessor):\n","        self.df['tokens'] = [preprocessor(s) for s in self.df['sentence']]\n","        self.df['tokens'] = [x[:self.padding_length]  if len(x) > self.padding_length else x for x in self.df['tokens']]\n","        # for index, row in self.df.iterrows():\n","        #     if len(row['tokens']) > self.max_length:\n","        #         row[toke]\n","\n","        ######## Changed part for negatives ###########\n","        self.token_to_count = Counter([x for l in self.df['tokens'] for x in l if x not in self.modifiers and x not in self.negatives])\n","        self.modifiers_to_count = Counter([x for l in self.df['tokens'] for x in l if x in self.modifiers])\n","        self.negatives_to_count = Counter([x for l in self.df['tokens'] for x in l if x in self.negatives])\n","        ##############      End       #################\n","\n","        # tmp_token_to_count = self.token_to_count.copy()\n","        # for index, value in tmp_token_to_count.items():\n","        #     if value <= self.vocab_frequency:\n","        #         self.token_to_count.pop(index)\n","        # self.df['tokens'] = [self.remove_low_frequency(x) for x in self.df['tokens']]\n","        self.max_length = self.get_max_length()\n","        print(f'Max Length : {self.max_length}')\n","\n","        ######## Changed part for negatives ###########\n","        self.vocab = list([[term] for term in self.token_to_count.keys()])\n","        self.modifier_vocab = list([[term] for term in self.modifiers_to_count.keys()])\n","        self.negative_vocab = list([[term] for term in self.negatives_to_count.keys()])\n","        self.modifier_token_to_id = {self.modifier_vocab[i][0]: i + 1 for i in range(len(self.modifier_vocab))}\n","        self.modifier_id_to_fit = list([[term] for term in self.modifier_token_to_id.values()])\n","        # self.negative_token_to_id = {self.negative_vocab[i][0]: i + 1 for i in range(len(self.negative_vocab))}\n","        # self.negative_id_to_fit = list([[term] for term in self.negative_token_to_id.values()])\n","        ##############      End       #################\n","\n","        print(f'Vocab Size : {len(self.vocab)}')\n","        print(f'Modifier Size : {len(self.modifier_vocab)}')\n","        print(f'Negative Size : {len(self.negative_vocab)}')\n","        # print(self.token_to_count)\n","\n","    def get_max_length(self):\n","        max_length = 0\n","        for index, row in self.df.iterrows():\n","            ######## Changed part for negatives ###########\n","            token_list = [x for x in row['tokens'] if x not in self.modifiers and x not in self.negatives]\n","            ##############      End       #################\n","            tmp_length = len(token_list)\n","            if tmp_length > max_length:\n","                max_length = tmp_length\n","        return max_length\n","\n","    def k_fold_partition(self, fold_num = 10):\n","        batch_size = int(len(self.train) / fold_num) # the number of data for each fold\n","        remain_num = len(self.train) - batch_size * fold_num # the remain data after partition\n","        self.fold_data = []\n","        fold_batch_list = [] # Average the remaining data to the folds\n","        for fold in range(fold_num):\n","          if remain_num > 0:\n","            remain_num -= 1\n","            fold_batch_list.append(batch_size + 1)\n","          else:\n","            fold_batch_list.append(batch_size)\n","        fold_index = 0 # The starting position of each division data\n","        for fold in range(fold_num):\n","          fold_texts = [fold_index, fold_index + fold_batch_list[fold]]\n","          self.fold_data.append(fold_texts)\n","          # print(f'fold_data : {fold_batch_list[fold]}')\n","          # print(f'fold_data type : {type(fold_batch_list[fold])}')\n","          # print(f'index type : {type(fold_index)}')\n","          fold_index = fold_index + fold_batch_list[fold]\n","\n","\n","    def k_fold_split(self, k):\n","        print(f'K : {k}, fold_data[k] : {self.fold_data[k]}')\n","        validation = self.train.iloc[self.fold_data[k][0]: self.fold_data[k][1]]\n","        train = self.train.iloc[0: self.fold_data[k][0]].append(self.train.iloc[self.fold_data[k][1]:])\n","        train_num = len(self.train) - (self.fold_data[k][1] - self.fold_data[k][0])\n","        if train_num % self.batch_size == 0:\n","            self.no_batch = train_num / self.batch_size\n","        else:\n","            self.no_batch = int(train_num / self.batch_size) + 1\n","        print(f' index : {self.no_batch}')\n","        return train, validation\n","\n","\n","\n","    def split(self, train, test):\n","        index = int(train * len(self.df))\n","        self.train = self.df.iloc[0:index]\n","        self.test = self.df.iloc[index:]\n","        # if self.train_index % self.batch_size == 0:\n","        #     self.no_batch = self.train_index / self.batch_size\n","        # else:\n","        #     self.no_batch = int(self.train_index / self.batch_size) + 1\n","        # print(f' index : {self.no_batch}')\n","\n","    def build_training_data(self, enc, df):\n","        X = []\n","        Y = []\n","        for index, row in df.iterrows():\n","            # build modifiers\n","            np_modifier = np.zeros(len(row['tokens']))\n","            np_negative = np.zeros(len(row['tokens']))\n","            for index, value in enumerate(row['tokens']):\n","                if value in self.modifiers:\n","                    id = self.modifier_token_to_id[value]\n","                    np_modifier[index] = -1\n","                    np_negative[index] = -1\n","                    for i in range(1, self.context_window + 1):\n","                        if index - i > 0:\n","                          if row['tokens'][index - i] not in self.modifiers and row['tokens'][index - i] not in self.negatives:\n","                            np_modifier[index - i] = id\n","                          else:\n","                            if index - i - 1 > 0 and row['tokens'][index - i - 1] not in self.modifiers and row['tokens'][index - i - 1] not in self.negatives:\n","                              np_modifier[index - i - 1] = id\n","                        if index + i < len(row['tokens']):\n","                          if row['tokens'][index + i] not in self.modifiers and row['tokens'][index + i] not in self.negatives:\n","                            np_modifier[index + i] = id\n","                          else:\n","                            if index + i + 1 < len(row['tokens']) and row['tokens'][index + i + 1] not in self.modifiers and row['tokens'][index + i + 1] not in self.negatives:\n","                              np_modifier[index + i + 1] = id\n","\n","                if value in self.negatives:\n","                    # The method uses np_negative[itself] = id - np_negative[itself] is to make\n","                    # sure that if there are two negative words, the switch will be twice\n","                    id = 1\n","                    np_negative[index] = -1\n","                    np_modifier[index] = -1\n","                    for i in range(1, self.context_window + 1):\n","                        if index - i > 0:\n","                          if row['tokens'][index - i] not in self.modifiers and row['tokens'][index - i] not in self.negatives:\n","                            np_negative[index - i] = id - np_negative[index - i]\n","                          else:\n","                            if index - i - 1 > 0 and row['tokens'][index - i - 1] not in self.modifiers and row['tokens'][index - i - 1] not in self.negatives:\n","                              np_negative[index - i - 1] = id - np_negative[index - i - 1]\n","                        if index + i < len(row['tokens']):\n","                          if row['tokens'][index + i] not in self.modifiers and row['tokens'][index + i] not in self.negatives:\n","                            np_negative[index + i] = id - np_negative[index + i]\n","                          else:\n","                            if index + i + 1 < len(row['tokens']) and row['tokens'][index + i + 1] not in self.modifiers and row['tokens'][index + i + 1] not in self.negatives:\n","                              np_negative[index + i + 1] = id - np_negative[index + i + 1]\n","                        \n","\n","\n","            ######## Changed part for negatives ###########\n","            # delete modifier and negative word\n","            deleted_index = [i for i in range(len(np_modifier)) if np_modifier[i] == -1]\n","            np_modifier = np.delete(np_modifier, deleted_index)\n","            np_negative = np.delete(np_negative, deleted_index)\n","\n","\n","            tmp = [enc.transform([[t]]).toarray()[0] for t in row['tokens'] if t not in self.modifiers and t not in self.negatives]\n","            for i in range(len(tmp)):\n","                tmp[i] = np.append(tmp[i], np_modifier[i])\n","                tmp[i] = np.append(tmp[i], np_negative[i])\n","            if len(tmp) < self.max_length:\n","                pad_length = self.max_length - len(tmp)\n","                for i in range(pad_length):\n","                    tmp.append(np.append(np.zeros(len(self.vocab)), [-1, 0]))\n","            ##############      End       #################\n","            X.append(tmp)\n","            Y.append(row['label'])\n","        X = np.array(X)\n","        Y = np.array(Y)\n","        X = torch.from_numpy(X).float()\n","        Y = torch.from_numpy(Y).long()\n","        print(f'Input Data Shape (sequence_num, sequence_len, vocab_size + 1) : {X.shape}')\n","        print(f'Input Label Shape : {Y.shape}')\n","        return X, Y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gOBWpAvWrAdh"},"source":["class RelexNet(nn.Module):\n","    #Single step RNN.\n","    #input_size is char_vacab_size=26,hidden_size is number of hidden neurons，output_size is number of categories\n","    def __init__(self, vocabulary_size, modifier_size, len_seq, num_classes, enc):\n","        super(RelexNet, self).__init__()\n","        self.no_modifiers = np.zeros(modifier_size)\n","        self.num_classes = num_classes\n","        self.L = nn.Linear(vocabulary_size, num_classes)\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.M = nn.Linear(modifier_size, 1).cuda()\n","        # self.B = nn.Linear(len_seq, len_seq)\n","        self.enc = enc\n","\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def handle_modifier(self, modifier_ids, batch):\n","        # modifier_id = modifier_ids.cpu()\n","        modifier = []\n","        influence_flag = []\n","        add = 0.5 * Variable(torch.ones(batch, 1))\n","        for i in range(batch):\n","            if modifier_ids[i] == 0:\n","                modifier.append(self.no_modifiers)\n","                influence_flag.append(0)\n","                add[i] = 1\n","            elif modifier_ids[i] == -1:\n","                modifier.append(self.no_modifiers)\n","                influence_flag.append(0)\n","                add[i] = 0\n","            else:\n","                # print(modifier_ids[i])\n","                modifier.append(self.enc.transform([[modifier_ids[i].cpu()]]).toarray()[0])\n","                influence_flag.append(1)\n","        modifier = torch.tensor(modifier).float().cuda()\n","        influence_flag = torch.tensor(influence_flag).float()\n","        influence_flag = influence_flag.reshape(-1, 1).cuda()\n","        add = add.cuda()\n","        return modifier, influence_flag, add\n","\n","\n","\n","    def forward(self, input, B_layer):\n","        # X.shape = (batch, seq_len, vocab_size)\n","        T = input.shape[1]\n","        batch = input.shape[0]\n","        predict_y = Variable(torch.zeros(batch, self.num_classes))\n","\n","        if B_layer is None:\n","            B_layer = Variable(torch.zeros(batch, self.num_classes)).cuda()\n","\n","        for t in range(T):\n","            tmp = input[:, t, :-2]\n","            modifier_ids = input[:, t, -2]\n","            negative_ids = input[:, t, -1]\n","            modifier, influence_flag, add = self.handle_modifier(modifier_ids, batch)\n","\n","            L_onestep = self.L(tmp)\n","            L_onestep = self.dropout(L_onestep)\n","            # L_onestep = torch.sigmoid(L_onestep)\n","            # L_onestep = MyReLU_PLUS.apply(L_onestep)\n","            L_onestep = F.relu6(L_onestep)\n","            modifier_score = torch.sigmoid(self.M(modifier))\n","            # modifier_score = torch.relu(self.M(modifier))\n","            modifier_score = modifier_score * influence_flag\n","            modifier_score = modifier_score + add\n","            # L_onestep = L_onestep + modifier_score\n","\n","            L_onestep = L_onestep * modifier_score\n","            # L_onestep = L_onestep * negative_score\n","\n","\n","            # This step is to switch the score of negative and positive\n","            # Using matrix operation is to guarantee the speed\n","            new_negative_ids = negative_ids.reshape(-1,1).repeat(1,2)\n","            all_exchanged_L_onestep = L_onestep[:,[1,0]]\n","            exchanged_L_onestep = all_exchanged_L_onestep * new_negative_ids + L_onestep * (1 - new_negative_ids)\n","\n","            B_layer = torch.add(B_layer, exchanged_L_onestep)\n","            # print(B_layer)\n","\n","            if self.num_classes == 1:\n","                predict_y[t] = F.sigmoid(B_layer)\n","            else:\n","                predict_y = self.softmax(B_layer)\n","\n","        return predict_y, B_layer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rE53K7W8sP4K"},"source":["def train_model(dataset, model, optimizer, scheduler, num_epochs, dev):\n","    losses = []\n","    for epoch in range(num_epochs):\n","        # training mode\n","        # dataset.set_partition(dataset.train)\n","        model.train()\n","        total_train_loss = 0\n","        total_train_correct = 0\n","        count = 0\n","        for x, y in dataset.train_dataset:\n","            # for every batch in the training dataset perform one update step of the optimizer.\n","            state = None\n","            model.zero_grad()\n","            y_h, state = model(x.to(dev), state)\n","            loss = F.cross_entropy(y_h, y.to(dev))\n","            optimizer.zero_grad()\n","            # scheduler.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            # print('{} optim: {}'.format(epoch, optimizer.param_groups[0]['lr']))\n","            scheduler.step()\n","            # print('{} scheduler: {}'.format(epoch, scheduler.get_lr()[0]))\n","            total_train_loss += loss.item()\n","            total_train_correct += (y_h.argmax(-1) == y.cuda()).float().mean()\n","            count += 1\n","        average_train_loss = total_train_loss / count\n","        average_train_accuracy = total_train_correct / count\n","        print('{} optim: {}'.format(epoch + 1, optimizer.param_groups[0]['lr']))\n","        \n","        losses.append(average_train_loss)\n","\n","\n","        print(f'epoch {epoch + 1} accuracies: \\t train: {average_train_accuracy}\\t loss: {average_train_loss}\\t')\n","\n","    # test mode\n","    # dataset.set_partition(dataset.test)\n","    model.eval()\n","    total_test_correct = 0\n","    count = 0\n","    for x, y in dataset.test_dataset:\n","        state = None\n","        y_h, state = model(x.to(dev), state)\n","        total_test_correct += (y_h.argmax(-1) == y.cuda()).float().mean()\n","        count += 1\n","    average_test_accuracy = total_test_correct / count\n","\n","    # print(f'test accuracy {average_test_accuracy} precision {average_precision} recall {average_recall}')\n","    print(f'test accuracy {average_test_accuracy}')\n","\n","    return losses, (average_train_accuracy, average_test_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SbWvcYEurRyy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622449599463,"user_tz":-480,"elapsed":459308,"user":{"displayName":"刘世萱","photoUrl":"","userId":"15293057863655146379"}},"outputId":"7bcfde2e-2afa-467a-d30b-2a0faf00cfb7"},"source":["num_epochs = 20\n","batch_size = 32  # Number of hidden neurons in model\n","context_window = 1\n","k = 9\n","\n","dev = 'cuda' if torch.cuda.is_available() else 'cpu'  # If you have a GPU installed, use that, otherwise CPU\n","print(dev)\n","print('Loading data...')\n","all_files = glob.glob(\"data/sentiment/*.csv\")\n","# all_files = glob.glob(\"*.csv\")\n","data = pd.concat((pd.read_csv(f, header=None, index_col=None) for f in all_files))\n","# path = os.path.join('data', 'sentiment', 'amazon_cells_labelled.csv')\n","# data = pd.read_csv(path)\n","data.columns = ['sentence', 'label']\n","data = data.sample(frac=1, random_state=1)\n","# data = shuffle(data)\n","dataset = DataLoader(data, k=k, batch_size = batch_size, context_window=context_window, dev=dev)\n","# print(f'Data Size: {dataset.df.size()}')\n","print(\"Data Ready!\")\n","vocabulary_size = len(dataset.vocab)\n","len_seq = dataset.max_length\n","num_classes = 2\n","\n","# model = FastText(len(dataset.token_to_id)+2, num_hidden, len(dataset.class_to_id)).to(dev)\n","model = RelexNet(vocabulary_size=vocabulary_size, enc=dataset.enc_modifiers, modifier_size=len(dataset.modifier_vocab),len_seq=len_seq, num_classes=num_classes).cuda()\n","# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n","optimizer = torch.optim.Adam(model.parameters(),lr=0.01,betas=(0.9,0.99))\n","# optimizer = torch.optim.Adam(model.parameters(),lr=0.01,betas=(0.9,0.99), weight_decay=10)\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[8 * dataset.no_batch, 14 * dataset.no_batch],gamma = 0.1, last_epoch=-1)\n","\n","losses, accuracies = train_model(dataset, model, optimizer, scheduler, num_epochs, dev=dev)\n","print(losses)\n","# torch.save(model, os.path.join('./relexnet_model_negative/classifier_M7.pth'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n","Loading data...\n","Max Length : 68\n","Vocab Size : 5251\n","Modifier Size : 34\n","Negative Size : 24\n","Input Data Shape (sequence_num, sequence_len, vocab_size + 1) : torch.Size([2700, 68, 5253])\n","Input Label Shape : torch.Size([2700])\n","Input Data Shape (sequence_num, sequence_len, vocab_size + 1) : torch.Size([300, 68, 5253])\n","Input Label Shape : torch.Size([300])\n","Train Dataset Shape : torch.Size([2700, 68, 5253])\n","Test Dataset Shape : torch.Size([300, 68, 5253])\n","Data Ready!\n","1 optim: 0.01\n","epoch 1 accuracies: \t train: 0.5486519932746887\t loss: 0.6836174845695495\t\n","2 optim: 0.01\n","epoch 2 accuracies: \t train: 0.6220588088035583\t loss: 0.6489814477808336\t\n","3 optim: 0.01\n","epoch 3 accuracies: \t train: 0.6498774290084839\t loss: 0.6265076146406285\t\n","4 optim: 0.01\n","epoch 4 accuracies: \t train: 0.6789215803146362\t loss: 0.6143849457011503\t\n","5 optim: 0.01\n","epoch 5 accuracies: \t train: 0.7150735259056091\t loss: 0.5995489036335665\t\n","6 optim: 0.01\n","epoch 6 accuracies: \t train: 0.7773284316062927\t loss: 0.5535064195885377\t\n","7 optim: 0.01\n","epoch 7 accuracies: \t train: 0.8142157196998596\t loss: 0.51522477795096\t\n","8 optim: 0.001\n","epoch 8 accuracies: \t train: 0.834313690662384\t loss: 0.4994484922465156\t\n","9 optim: 0.001\n","epoch 9 accuracies: \t train: 0.84375\t loss: 0.48546934232992284\t\n","10 optim: 0.001\n","epoch 10 accuracies: \t train: 0.834313690662384\t loss: 0.4860730241326725\t\n","11 optim: 0.001\n","epoch 11 accuracies: \t train: 0.8490195870399475\t loss: 0.4826932577525868\t\n","12 optim: 0.001\n","epoch 12 accuracies: \t train: 0.8405637145042419\t loss: 0.482840218964745\t\n","13 optim: 0.001\n","epoch 13 accuracies: \t train: 0.8400735259056091\t loss: 0.4851737653507906\t\n","14 optim: 0.0001\n","epoch 14 accuracies: \t train: 0.8474264740943909\t loss: 0.4816518706433913\t\n","15 optim: 0.0001\n","epoch 15 accuracies: \t train: 0.8474264740943909\t loss: 0.48309096203130836\t\n","16 optim: 0.0001\n","epoch 16 accuracies: \t train: 0.8397058844566345\t loss: 0.4819712617818047\t\n","17 optim: 0.0001\n","epoch 17 accuracies: \t train: 0.856985330581665\t loss: 0.47287974673158983\t\n","18 optim: 0.0001\n","epoch 18 accuracies: \t train: 0.8501225113868713\t loss: 0.47593564391136167\t\n","19 optim: 0.0001\n","epoch 19 accuracies: \t train: 0.8387254476547241\t loss: 0.48139859928804285\t\n","20 optim: 0.0001\n","epoch 20 accuracies: \t train: 0.8507353067398071\t loss: 0.4769369710894192\t\n","test accuracy 0.824999988079071\n","[0.6836174845695495, 0.6489814477808336, 0.6265076146406285, 0.6143849457011503, 0.5995489036335665, 0.5535064195885377, 0.51522477795096, 0.4994484922465156, 0.48546934232992284, 0.4860730241326725, 0.4826932577525868, 0.482840218964745, 0.4851737653507906, 0.4816518706433913, 0.48309096203130836, 0.4819712617818047, 0.47287974673158983, 0.47593564391136167, 0.48139859928804285, 0.4769369710894192]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xzzcdPQuRcyw"},"source":[""],"execution_count":null,"outputs":[]}]}